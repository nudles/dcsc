{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural network (RNN) for sentiment analysis\n",
    "\n",
    "### Problems of using CNN for NLP tasks?\n",
    "\n",
    "![cnn-senti.png](attachments/cnn-senti.png)\n",
    "\n",
    "\n",
    "### RNN is good at processing sequences of variable length\n",
    "\n",
    "![rnn-unfold.png](attachments/rnn-unfold.png)\n",
    "\n",
    "\n",
    "### Architecture of RNN for sentiment analysis\n",
    "\n",
    "![rnn-sent.png](attachments/rnn-sent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare text data\n",
    "\n",
    "The imdb dataset is used here again for sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 train sequences\n",
      "25000 test sequences\n",
      "x_train shape:  (25000, 80)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.preprocessing import sequence\n",
    "from keras.datasets import imdb\n",
    "\n",
    "\n",
    "max_features = 2000\n",
    "maxlen = 80  # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32\n",
    "hidden_size = 64\n",
    "embedding_size = 32\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(\n",
    "    num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print(\"x_train shape: \", x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model \n",
    "\n",
    "* Each word is represented by a vector of length max_features by the embedding layer, and then fed into the RNN unit.\n",
    "* The hidden feature of the RNN unit is then fed into a linear feature transformation layer (Dense), which generates a single value reprenting the score for being postive.\n",
    "* The final activation layer normalize the score to be within (0, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 80, 32)            64000     \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 64)                6208      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 70,273\n",
      "Trainable params: 70,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import SimpleRNN\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_size, \n",
    "                    mask_zero=True, input_length=maxlen))\n",
    "model.add(SimpleRNN(hidden_size, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training \n",
    "\n",
    "* loss function: binary_crossentropy is $-tlogp - (1-t)log(1-p)$, where t=1 if the true label is positive; otherwise 0.\n",
    "* optimizer (SGD): Adam\n",
    "* metric: Accuracy = num of correct prediction / num of total samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 93s 4ms/step - loss: 0.6976 - acc: 0.5409 - val_loss: 0.7799 - val_acc: 0.5426\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 90s 4ms/step - loss: 0.6661 - acc: 0.5920 - val_loss: 0.7039 - val_acc: 0.5390\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 91s 4ms/step - loss: 0.6505 - acc: 0.6097 - val_loss: 0.6409 - val_acc: 0.6199\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 90s 4ms/step - loss: 0.6279 - acc: 0.6334 - val_loss: 0.6292 - val_acc: 0.6274\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 91s 4ms/step - loss: 0.6040 - acc: 0.6687 - val_loss: 0.5962 - val_acc: 0.6654\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 90s 4ms/step - loss: 0.6034 - acc: 0.6597 - val_loss: 0.6398 - val_acc: 0.6314\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 90s 4ms/step - loss: 0.6051 - acc: 0.6621 - val_loss: 0.7467 - val_acc: 0.5478\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 90s 4ms/step - loss: 0.6014 - acc: 0.6728 - val_loss: 0.6934 - val_acc: 0.5634\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 90s 4ms/step - loss: 0.6053 - acc: 0.6726 - val_loss: 0.6586 - val_acc: 0.6537\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 90s 4ms/step - loss: 0.6195 - acc: 0.6515 - val_loss: 0.6715 - val_acc: 0.6146\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "# try using different optimizers and different optimizer configs\n",
    "optimizer = RMSprop(lr=0.01, clipnorm=5.)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train, batch_size=batch_size, \n",
    "          epochs=10, validation_data=(x_test, y_test))\n",
    "model.save_weights('ckpt/simplernn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Unit\n",
    "\n",
    "![vanilla-rnn.png](attachments/vanilla-rnn.png)\n",
    "\n",
    "$$h_t = f(h_{t-1}, x_t|\\Theta)$$\n",
    "\n",
    "* Vanilla RNN\n",
    "* LSTM\n",
    "* GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla RNN\n",
    "\n",
    "$$h_t = a(h_{t-1}U+x_tW+b)$$\n",
    "$$x_t \\in R^{d_x}, h_t\\in R^{d_h}, U\\in R^{d_h \\times d_h}, W\\in R^{d_x \\times d_h}$$\n",
    "a() = tanh, ReLu, Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "class VanillaRNNCell(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, units, **kwargs):\n",
    "        self.units = units\n",
    "        self.state_size = units\n",
    "        super(VanillaRNNCell, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \"\"\"Create weight matrix\"\"\"\n",
    "        self.W = self.add_weight(shape=(input_shape[-1], self.units), initializer='uniform', name='kernel')\n",
    "        self.U = self.add_weight(shape=(self.units, self.units), initializer='uniform', name='recurrent_kernel')\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, states):\n",
    "        \"\"\"Called per position/timestep for a batch of data\"\"\"\n",
    "        prev_output = states[0]\n",
    "        h = K.dot(inputs, self.W)\n",
    "        output = h + K.dot(prev_output, self.U)\n",
    "        # can also add dropout here\n",
    "        return output, [output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 118s 5ms/step - loss: 0.5578 - acc: 0.7023 - val_loss: 0.4414 - val_acc: 0.793416 - acc: 0. - ETA: 1s - loss: 0.5604 - \n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 112s 4ms/step - loss: 0.3524 - acc: 0.8480 - val_loss: 0.4130 - val_acc: 0.8098\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 111s 4ms/step - loss: 0.2150 - acc: 0.9178 - val_loss: 0.4800 - val_acc: 0.8216\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 111s 4ms/step - loss: 0.1229 - acc: 0.9555 - val_loss: 0.5977 - val_acc: 0.7938\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 112s 4ms/step - loss: 0.1051 - acc: 0.9609 - val_loss: 0.7090 - val_acc: 0.7905\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 112s 4ms/step - loss: 0.0656 - acc: 0.9754 - val_loss: 0.7576 - val_acc: 0.7539\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 112s 4ms/step - loss: 2.0046 - acc: 0.8639 - val_loss: 6.6009 - val_acc: 0.5884\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 112s 4ms/step - loss: 6.1526 - acc: 0.6164 - val_loss: 6.6009 - val_acc: 0.5884\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 111s 4ms/step - loss: 6.1526 - acc: 0.6164 - val_loss: 6.6009 - val_acc: 0.5884\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 111s 4ms/step - loss: 6.1526 - acc: 0.6164 - val_loss: 6.6009 - val_acc: 0.5884\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import RNN, Embedding, Dense\n",
    "from keras import Sequential\n",
    "from keras import backend as K\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_size, \n",
    "                    mask_zero=True, input_length=maxlen))\n",
    "model.add(RNN(VanillaRNNCell(hidden_size)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train, batch_size=batch_size, \n",
    "          epochs=10, validation_data=(x_test, y_test))\n",
    "model.save_weights('ckpt/vanilla.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM\n",
    "\n",
    "![lstm1.png](attachments/lstm1.png)\n",
    "![lstm2.png](attachments/lstm2.png)\n",
    "![lstm3.png](attachments/lstm3.png)\n",
    "![lstm4.png](attachments/lstm4.png)\n",
    "\n",
    "**Gate + States**\n",
    "![lstm5.png](attachments/lstm5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 349s 14ms/step - loss: 0.4621 - acc: 0.7838 - val_loss: 0.4432 - val_acc: 0.7942\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 342s 14ms/step - loss: 0.2977 - acc: 0.8782 - val_loss: 0.3757 - val_acc: 0.8359\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 343s 14ms/step - loss: 0.2174 - acc: 0.9159 - val_loss: 0.4441 - val_acc: 0.8303\n",
      "Epoch 4/10\n",
      "20736/25000 [=======================>......] - ETA: 40s - loss: 0.1470 - acc: 0.9463"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 340s 14ms/step - loss: 0.0332 - acc: 0.9890 - val_loss: 0.7682 - val_acc: 0.8194\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 342s 14ms/step - loss: 0.0284 - acc: 0.9906 - val_loss: 0.8560 - val_acc: 0.8175\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM, Embedding, Dense\n",
    "from keras.models import Sequential\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_size, \n",
    "                    mask_zero=True, input_length=maxlen))\n",
    "model.add(LSTM(hidden_size, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          validation_data=(x_test, y_test))\n",
    "model.save_weights('ckpt/lstm.h5')\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU\n",
    "\n",
    "![gru.png](attachments/gru.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 395s 16ms/step - loss: 0.4667 - acc: 0.7762 - val_loss: 0.4097 - val_acc: 0.8158\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 390s 16ms/step - loss: 0.2912 - acc: 0.8800 - val_loss: 0.3567 - val_acc: 0.8435\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import GRU\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_size, \n",
    "                    mask_zero=True, input_length=maxlen))\n",
    "model.add(GRU(hidden_size, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=2, \n",
    "          validation_data=(x_test, y_test))\n",
    "model.save_weights('ckpt/gru.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN training tricks\n",
    "\n",
    "* Adaptive learning rate\n",
    "* E.g. Adam, RMSProp\n",
    "* Normalizing the losses\n",
    "* Use gated RNN units\n",
    "* LSTM or GRU (not introduced yet)\n",
    "* Stack multiple RNN layers\n",
    "![rnn-stacks.png](attachments/rnn-stacks.png)\n",
    "![bptt.png](attachments/bptt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN for language modelling\n",
    "\n",
    "Lauage modelling is to generate words/sentences\n",
    "\n",
    "$$P(w_n|w_{n-1}, w_{n-2}, ..., w_1)$$\n",
    "\n",
    "Applicaitons including\n",
    "* Machine translation\n",
    "* Question answering\n",
    "* Image caption generation\n",
    "\n",
    "\n",
    "## CharRNN\n",
    "\n",
    "To generate sentences automatically, e.g. for papers, novels, code, etc.\n",
    "\n",
    "![rnn-ti.png](attachments/rnn-ti.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downlaod the text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "path = get_file('nietzsche.txt', \n",
    "                origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "text = open(path, encoding=\"utf-8\").read().lower()  # encoding=\"utf-8\")\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create char to index and index to char mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 57\n",
      "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'ä', 'æ', 'é', 'ë']\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "print(chars)\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert chars into batches of one-hot representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 200285\n",
      "Vectorization...\n",
      "x shape: (200285, 40, 57)\n",
      "y shape: (200285, 57)\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1 \n",
    "print(\"x shape:\", x.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "# build the model: a single LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "#model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01, clipnorm=5.)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/1\n",
      "200285/200285 [==============================] - 106s 529us/step - loss: 2.0317\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"l and witness of every act, every moment\"\n",
      "l and witness of every act, every moment the most the self--and the condince of the condince of the such and the seem to the such a the self--in the such a strended to the self the condince to the most and such a nother the self--and the such a stance the most the condince of the most the most the condition of the constince the most of the contrance to the conture of the self--in the serves of the excerture to the such a so the men the \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"l and witness of every act, every moment\"\n",
      "l and witness of every act, every moment to fired to the would the constance of self--and points not the excectus in mean and has one with the regreated, and as with a fine the conception of the matter of they every for the surt decestion, in the exception to be the contruent of the such and in the self--in so contrife degentions of the to a servent to in the\n",
      "man in the effection the time the indies, or the soce to act in the contemple \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"l and witness of every act, every moment\"\n",
      "l and witness of every act, every moments ficl if orringications wat gerere to when hene, eurst and ac peintle ells, rangalg of truthic, with philosopher and as alm traging courd than eirchire (to condect a servete more for knom the greot the the asrument the surde free found by howents he the excecist aring\n",
      "thatminess take it is nement funic so-resciriture\n",
      "theme has to sneely becialy. the\n",
      "the\n",
      "highing, they, and perind shoughtemor,\n",
      "they\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"l and witness of every act, every moment\"\n",
      "l and witness of every act, every momentiah vict.an, must,, uncerant diwe'nand in\n",
      "hom. (it forly, as con-to be thery witume one is wime, w lituined\n",
      "if way\n",
      "have more when for or eank. the pocibiss, heself invieflessele tring the simms; with hat for\n",
      "has it take-whene\n",
      "mest\n",
      "and\n",
      "seto\n",
      "holpelte=ther, and lepeopere, amsefrece: to convirts, recresese, oncy\n",
      "knoul, it faryour attelies homsild genturbe: \"pincy not it\n",
      "plight, understisness) our1fare\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/1\n",
      "200285/200285 [==============================] - 105s 527us/step - loss: 1.6682\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \", when it is\n",
      "the rulers who determine th\"\n",
      ", when it is\n",
      "the rulers who determine the prosely the sention of the more and an instance and a man in the prosely and in the stronger the sented and an art of the sention of the sention of the present and an art and be the prosely and an instance of the more new the experience and and a man in the sention of the sention of the experience of the sention of the strenged and one is a stronger and an and an instance of the strengs and in t\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \", when it is\n",
      "the rulers who determine th\"\n",
      ", when it is\n",
      "the rulers who determine the stands and present the the prosely a stated to its falled that the high one's and suffering and flame and an instance and an instance of the action or the present conscience in the something and a something and not of the sopere of the aman of the soul of the most and do the prosely the casted for the the of the strengs and nature of and of the sent of the simple and not the religious and conduc\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \", when it is\n",
      "the rulers who determine th\"\n",
      ", when it is\n",
      "the rulers who determine thereven only not on intentrut along cekenies and conditions, moralshing the unressote, finders the can or the living notsonectionay fins in the religate of means indeed of dangeration of posse, species will nor\n",
      "for the has not which a long adpessed. it has religiount of the laws the praite and as reflumar of demailing for with other is can gain from is when it is the seasial one upon is tyen, an os\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \", when it is\n",
      "the rulers who determine th\"\n",
      ", when it is\n",
      "the rulers who determine the wnouthrnase. se\n",
      "pragle, toce, on a nher opocighes.\"--addantinghod, to jutt (horemses by fourso when exaire sicsy\n",
      "men ourseld, herely palte howef\n",
      "indeals wfer simpronst of drests\n",
      "no bleven\"\n",
      "gene bonk exersianes who\n",
      "uadly best party ut socitamon of usught titentiof--almost implase philosophed utable laugory in dedectain the\n",
      "act time hif\n",
      "plooind oopher an thigh thrips. thing any is are dought right\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/1\n",
      "200285/200285 [==============================] - 106s 528us/step - loss: 1.5783\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ous test\n",
      "when something passes by that i\"\n",
      "ous test\n",
      "when something passes by that it is a constitute to the more of the spirits of the will to the spect of the stands the spirits of the stard to the stands and and all the who only and as the moral to the more of the where the world to the still the for the consequently and all the who has the stands of the who are the the stands of the constitute of the stands of the stands of the stands and the word to the moral to and constitu\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ous test\n",
      "when something passes by that i\"\n",
      "ous test\n",
      "when something passes by that it were and the who love, have of the endived in\n",
      "the stands of his exceptions but of the for the to be consequently to the will as the adder to soul\"\" blood of this always the reason of the world, himself is the asmete of the propicion of the be stand, the being and deligions even these the moral of the stands in the denking and it all the donse to whe even and it be expression of the necessary and\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ous test\n",
      "when something passes by that i\"\n",
      "ous test\n",
      "when something passes by that in?o knows be philosophering\n",
      "and calse only soul, its schence manivelw of the potsiblend! which that and ebseds and dislemate feel myst for hcleal\n",
      "pitound\n",
      "cuntly exception leasoss good, on a migrrained hour who was more ourselves and esceptiusly a sprifteribly. what the\n",
      "rimklong its astenies, not its ewer by the degreens as nothing, as hold to \n",
      "thd find\n",
      "fear only pule elsies; much purse obtandangld\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ous test\n",
      "when something passes by that i\"\n",
      "ous test\n",
      "when something passes by that is avort for ausi-spamec: woervemed\n",
      "action to muck! if for all\n",
      "precesso invehtive: thinguar; upioded alto beth if the influe\n",
      "py irdiouet mudem as a lost eleffer asleschy for for cevence!\n",
      "with the philosophers and\n",
      "didm \"memmennationsd ard as alward neeked of humanited\"\n",
      "may purnousle hands ied them,iy good oflatan of bad, love, of stuth: soid aveins, with considen to dad, ay, that forst, all but fuld\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Epoch 1/1\n",
      "200285/200285 [==============================] - 106s 528us/step - loss: 1.5359s - loss: - ETA: 2s  -\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"s boldness of taste, which takes\n",
      "sufferi\"\n",
      "s boldness of taste, which takes\n",
      "suffering the same present that it is always and always and always and as a fact and more and the consequence of the profend to the word and action of the consideration of the soul of the consequence and ascender to the sense of the same the same preservation of the feeling and strength of the preservation of the preservation of the something and preservation and preservation of the present and the sense\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"s boldness of taste, which takes\n",
      "sufferi\"\n",
      "s boldness of taste, which takes\n",
      "suffering and convention even that is feeling man is the\n",
      "free will put a preserval the the disconsitide--and with something man and with all the master of the understorm the greating of the light the extens of the case and ascendence of all the sensible and finally there is a profine the he fact as the expression of the ears and ascensibilian to we recising the portent the\n",
      "individuality and ascendance of\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"s boldness of taste, which takes\n",
      "sufferi\"\n",
      "s boldness of taste, which takes\n",
      "suffering that even of the\n",
      "conviim and knywes of not besence of the\n",
      "litule\n",
      "concern\n",
      "and weaks the easy this valud they as befoot, whether an, herething\n",
      "condition,ghle, dow even new, and as\n",
      "a greater\n",
      "spirit,\" the work and\n",
      "spirius\n",
      "congratisl-indiffictly, instructions,\n",
      "not only amough of notive which alsozict to kinds yceam as is dored the\n",
      "near life?--upon has to life. their sc unting poding how\n",
      "vosimable,\" \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"s boldness of taste, which takes\n",
      "sufferi\"\n",
      "s boldness of taste, which takes\n",
      "suffering ancinichy freating of the wild anounced tend acmidine hope, that is thus delicace an oreds\n",
      "a\n",
      "veryount, the to not were is the\n",
      "worsthond blighthelly nature, of too nature andys, and becomlocrezantlitsusey rier to\n",
      "beragely-ides\n",
      "of decepialing.red custume unsometipl mind: and\n",
      "even subytens, as profects absolutels standions with is nothily\n",
      "intelien have aga, the peassmenence \" all to knowledges? po\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Epoch 1/1\n",
      "200285/200285 [==============================] - 106s 528us/step - loss: 1.5115\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"e tendency of the man of knowledge, whic\"\n",
      "e tendency of the man of knowledge, which are the most art the most invention and other and the most and intention of the same the sense of the sense of the constantly and conscience of the constant into the constantly and the respect of the higher more all the belongs of the constitution the sense of the most exception of the most are and instruction of the profound and have the most something and as the standing and all the most and t\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"e tendency of the man of knowledge, whic\"\n",
      "e tendency of the man of knowledge, which are new morals to the most and all higher the master, and experientty and at last most are be act of the antirmed by the self all the contempt and same which some them of the most belong to the more men and ascect of the stands only the sense of\n",
      "attempting of the religion, which it passion--they not the which the standing into the present and inverse of the most certaines, the general even the s\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"e tendency of the man of knowledge, whic\"\n",
      "e tendency of the man of knowledge, which means for belong creacurs for veligious that maniciggle admaticism out, and enticiented of goned the capable relation of moral as\n",
      "he ifsgending--deparding, arciled and always as\n",
      "desistity aride someing\n",
      "ganow to love of instruming andolually belong in fachhose outs darilize conscience--the maty, ple\" over theymed to men amose, rule retepes.\n",
      "\n",
      "\n",
      "11mithing pe a frert reveng his eventame sense\n",
      "ma, som\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"e tendency of the man of knowledge, whic\"\n",
      "e tendency of the man of knowledge, which\n",
      "an very first from it, and movemations upon the laith\"--elrated for \"chysterimen\n",
      "ashizity of myscuriom it is oh not \n",
      "volrances it thoughtded, eosentar was he such any other perhaps deconsity, conspition? men loves operoed known illines.--it \"youch intencion\n",
      "had moreive anywared--that\n",
      "frueddem that ot here an, als inful no \"the tarks to he serenth into atherers cratedness, they lookere men, wes p\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Epoch 1/1\n",
      "200285/200285 [==============================] - 107s 533us/step - loss: 1.4937\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"e espouses\n",
      "upon principle the cause agai\"\n",
      "e espouses\n",
      "upon principle the cause against the surferd the most the sancting the consciousness of the profounded the suppose and instinct of the profound the consciousness, the most the surfort, and and strange the surpose of the sensed to the will to the consciousness of the profounded to the profound the the profound the consciousness of the world to the strive of the consciousness of the surferst of the profound the profound the thi\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"e espouses\n",
      "upon principle the cause agai\"\n",
      "e espouses\n",
      "upon principle the cause against the truth in the love the does life intellectual with the more \"the world, as they has not the most the spirits to the\n",
      "higher also inderention of the delicate and learns, with he profound the life the case in the conscious of the senting in the loftering to the more understand the interpretations in the namely the something to the thus and possible of the delicate intellectual the can prehende\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"e espouses\n",
      "upon principle the cause agai\"\n",
      "e espouses\n",
      "upon principle the cause against even a compor, portonary suspination and goodmance to believed upon the usce him therefore and long the berne\" in the\n",
      "case in the to the outly, then and with men and alone, the may is primidetes thee mactive, and in this super of suffacce much\" must\n",
      "an\n",
      "artion is a phaptedor\"--if is, to thint that is theelly, in it\n",
      "everything entule acts of naising, one were will\n",
      "womank? but whom who cannf\n",
      "thd \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"e espouses\n",
      "upon principle the cause agai\"\n",
      "e espouses\n",
      "upon principle the cause against, ispur, the distrose\" appponow indeed hone-olained personan of the mose, that is acts of seemer of thesely\n",
      "to about\n",
      "pleaming gloy incording to\n",
      "understand in\n",
      "this because of i spepous and will\n",
      "need thos weal will coult-iarping than incealec mear and this conscioution is\n",
      "a siluntleum, every othand ceasericsing evil yems to so instance do not by really; back again a makem, do many, and hod nacisl\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Epoch 1/1\n",
      "200285/200285 [==============================] - 106s 532us/step - loss: 1.4792\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"tions\n",
      "he cannot attain. he is confiding,\"\n",
      "tions\n",
      "he cannot attain. he is confiding, and the process of the morality, in the most party the morality of the fact, the contradity in the contradity in the case the particion of the sense of the sense of the consibility of the contradity in the contradice of the contradity in the sense of the morality of the soul of the contradity to the consibining the contradity in the contradity and man in the possible the world to the sense of the\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"tions\n",
      "he cannot attain. he is confiding,\"\n",
      "tions\n",
      "he cannot attain. he is confiding, when it is the deligice to exception. the conceits of the weagermpician of an and contradity, and edication of his propound in the most andihing to him in himself; the standards it is so the the extent and helving to a perspeciation and morality, and and the most\n",
      "metable and his partician extending of the case the found that i morality and possible the excotent and of the contradiction of the inv\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"tions\n",
      "he cannot attain. he is confiding,\"\n",
      "tions\n",
      "he cannot attain. he is confiding, professike--ruling that on chanced? thus of\n",
      "the blang underchowness, maga \"helvation of readiness, it\n",
      "ow neases restally conducts and \"belief the contrable of\n",
      "propounds to di?--the think overwaheght\n",
      "the iker nation, or fay reads the ryss that the pathed thinking\n",
      "togrin of knowledge is truth; perhaps fools the most nothing other is ass\n",
      "ocknow-case and and embititimive and wavating thereby an eto n\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"tions\n",
      "he cannot attain. he is confiding,\"\n",
      "tions\n",
      "he cannot attain. he is confiding, with motateras arcerobly ove -and on resubt of cemphial humiuntey harf best tepolet-!unhive pulpociomed is to do enquoives! thins.on might of last natere. the catoxinous which\n",
      "dasi for shkin\n",
      "realy and vainw ancient of\n",
      "their estrustop?--the dogeth simulowlessific he\n",
      "beli wors, chileatho\n",
      "of\n",
      "means of the verninglo and at an eppondua casc dan\n",
      "stay-didless. brind; times.. nota\" its upticism life and a\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Epoch 1/1\n",
      "200285/200285 [==============================] - 106s 530us/step - loss: 1.4698\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" will be different!\n",
      "\n",
      "215. as in the stel\"\n",
      " will be different!\n",
      "\n",
      "215. as in the stell with the extent and so the man and and always and the substing of the sentiment and so the present that the world of the and and and and and and in the conditions of the religion of the same to the religion of the desire and always the end that the the sense of the the senting the subtles the strength and senting the soul of the present and and and as the end and and in the same and and and an a\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" will be different!\n",
      "\n",
      "215. as in the stel\"\n",
      " will be different!\n",
      "\n",
      "215. as in the stell, as the monsitian now it in the consequently the entire themselves experient and self-delight and dispose of the always alcond by the end that they more interested and reflections and substinises which is a necessary, which is not the end that the serves of the sublime must we easient and sentiments the heart, and and as the earth of so a sinds and in the\n",
      "his to be man in the\n",
      "elitter of the pres\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" will be different!\n",
      "\n",
      "215. as in the stel\"\n",
      " will be different!\n",
      "\n",
      "215. as in the stell a pleasure and face, only more denided in orderstar\n",
      "appearly\n",
      "flavjer hy continus dowar as\n",
      "remast; and the end--to commthlactoring strength have of\n",
      "flight that\n",
      "in natures arong in the necessary of\n",
      "same much standing his way revent out or in, attachire will, that it is confusual to him fament in syments, the minity which regarded to the good with while is errable. in him. the neter are condention.\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" will be different!\n",
      "\n",
      "215. as in the stel\"\n",
      " will be different!\n",
      "\n",
      "215. as in the stell not evolver,, haves mlangenness, \n",
      "fundance, an aws also is a sentarility; more value how\n",
      "thee novely believing in enapsless, on the odoged\n",
      "gorens and intuing ahwiar asgent, will eor sense--is not him, it is god\n",
      "ode, and mire: this laught, naps ob\n",
      "ofigated taste-know that the genius,\n",
      "probable it end, from plat religious play famul did\n",
      "by impulse of the rurned. most become lack of the shoust that \n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Epoch 1/1\n",
      "200285/200285 [==============================] - 107s 532us/step - loss: 1.4594\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ng he himself must perhaps have been cri\"\n",
      "ng he himself must perhaps have been cried the considered and fact to something of the presentes of the strength of the prosent and the propount that the sufficient or the fact that it is a strange the spirit of the prose of the significance of the same to the strength, the strength of the conscience of the and and and and and and a strength, and the present fact of the most strive of the prosent the constantly and and and and and and a\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ng he himself must perhaps have been cri\"\n",
      "ng he himself must perhaps have been cried the suffer and fact of the attained and condition of the preasially the problem the herded and and the instincts things of the end that the first of the most the condition of the properness and other every be understand and the proper hand to suffer and soul\n",
      "of the necessary and to pristure to advantage and constraint and greeks even of an a more every writer\n",
      "pravirity of which his deciding and\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ng he himself must perhaps have been cri\"\n",
      "ng he himself must perhaps have been criting of all of very caush the muristed, trifes the prise man\"\n",
      "enougics: more\n",
      "at the schopens\n",
      "than that it obsmolutisong what througho a powerful until conditions contrament to softhfulne, and hand? and\n",
      "son neither greaning, that does praile, make thank to this assumition throughous? rich out thought appear and head, endived.\"\n",
      "\n",
      "\" saily and di, he the sadience that it fre especially of a"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/hd1/home/wangwei/miniconda2/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:4: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nd usced of \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ng he himself must perhaps have been cri\"\n",
      "ng he himself must perhaps have been crieate won life\n",
      "langinging to we kiln as entive understand.agrve and and inderious for thinald behool. iazfrorave pist clumons. it sufey thet rate least, even a faludial to vove despaw\n",
      "cress' have cruelting that mar. europ! wath compless of great appearance iftacthe possenking\n",
      "asting and it stugung of\n",
      "our domant that constlect and stroyen\n",
      "imprevailive whict rellgypport?\n",
      "\n",
      "\"le thee sympathy, science w\n"
     ]
    }
   ],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "# train the model, output generated text after each iteration\n",
    "for iteration in range(1, 10):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(x[0:x.shape[0]//10], y[0:x.shape[0]//10],\n",
    "              batch_size=128,\n",
    "              epochs=1)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "print()\n",
    "model.save_weights('ckpt/charnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2seq model\n",
    "\n",
    "For machine translation\n",
    "\n",
    "![seq2seq.png](attachments/seq2seq.png)\n",
    "\n",
    "Download the [data](http://www.manythings.org/anki/fra-eng.zip) and extract the file into `data/fra-eng/fra.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 10000\n",
      "Number of unique input tokens: 71\n",
      "Number of unique output tokens: 93\n",
      "Max sequence length for inputs: 16\n",
      "Max sequence length for outputs: 59\n",
      "encoder_input_data shape:  (10000, 16, 71)\n",
      "decoder_input_data shape:  (10000, 59, 93)\n",
      "decoder_target_data shape:  (10000, 59, 93)\n",
      "input text sample: ['Go.', 'Run!', 'Run!']\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import fraeng\n",
    "\n",
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 3  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples = 10000  # Number of samples to train on.\n",
    "\n",
    "(encoder_input_data, decoder_input_data, decoder_target_data, \n",
    " input_token_index, target_token_index, input_texts) = fraeng.load_data(num_samples)\n",
    "\n",
    "print(\"encoder_input_data shape: \", encoder_input_data.shape)\n",
    "print(\"decoder_input_data shape: \", decoder_input_data.shape)\n",
    "print(\"decoder_target_data shape: \", decoder_target_data.shape)\n",
    "print(\"input text sample:\", input_texts[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_encoder_tokens = len(input_token_index)\n",
    "num_decoder_tokens = len(target_token_index)\n",
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.9255 - val_loss: 0.9709\n",
      "Epoch 2/3\n",
      "8000/8000 [==============================] - 16s 2ms/step - loss: 0.7327 - val_loss: 0.7901\n",
      "Epoch 3/3\n",
      "8000/8000 [==============================] - 16s 2ms/step - loss: 0.6237 - val_loss: 0.7228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/hd1/home/wangwei/miniconda2/envs/py36/lib/python3.6/site-packages/Keras-2.1.1-py3.6.egg/keras/engine/topology.py:2344: UserWarning: Layer lstm_3 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_2/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_2/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.fit([encoder_input_data, decoder_input_data], \n",
    "          decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)\n",
    "# Save model\n",
    "model.save('ckpt/s2s.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Fire!\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Jump.\n",
      "Decoded sentence: Arerez !\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Je me suis pas aite.\n",
      "\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence: Je me suis pas aite.\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Je me suis pas aite.\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Je me suis pas aite.\n",
      "\n",
      "-\n",
      "Input sentence: Oh no!\n",
      "Decoded sentence: Tome te te te paite.\n",
      "\n",
      "-\n",
      "Input sentence: Attack!\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Attack!\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Arenez de cous !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Arenez de cous !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Arenez de cous !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Arenez de cous !\n",
      "\n",
      "-\n",
      "Input sentence: Get up.\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Hop in.\n",
      "Decoded sentence: Arenez !\n",
      "\n",
      "-\n",
      "Input sentence: Hop in.\n",
      "Decoded sentence: Arenez !\n",
      "\n",
      "-\n",
      "Input sentence: Hug me.\n",
      "Decoded sentence: Nous aites aite.\n",
      "\n",
      "-\n",
      "Input sentence: Hug me.\n",
      "Decoded sentence: Nous aites aite.\n",
      "\n",
      "-\n",
      "Input sentence: I fell.\n",
      "Decoded sentence: Je me suis pas aite.\n",
      "\n",
      "-\n",
      "Input sentence: I fell.\n",
      "Decoded sentence: Je me suis pas aite.\n",
      "\n",
      "-\n",
      "Input sentence: I know.\n",
      "Decoded sentence: Je me suis pas aite.\n",
      "\n",
      "-\n",
      "Input sentence: I left.\n",
      "Decoded sentence: Je me suis pas aite.\n",
      "\n",
      "-\n",
      "Input sentence: I left.\n",
      "Decoded sentence: Je me suis pas aite.\n",
      "\n",
      "-\n",
      "Input sentence: I lost.\n",
      "Decoded sentence: Je me suis pas aite.\n",
      "\n",
      "-\n",
      "Input sentence: I'm 19.\n",
      "Decoded sentence: Je me suis pas aite.\n",
      "\n",
      "-\n",
      "Input sentence: I'm OK.\n",
      "Decoded sentence: Je me suis pas aite.\n",
      "\n",
      "-\n",
      "Input sentence: I'm OK.\n",
      "Decoded sentence: Je me suis pas aite.\n",
      "\n",
      "-\n",
      "Input sentence: Listen.\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: Arestez !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: Arestez !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: Arestez !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: Arestez !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: Arestez !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: Arestez !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: Arestez !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: Arestez !\n",
      "\n",
      "-\n",
      "Input sentence: Really?\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Really?\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Really?\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Thanks.\n",
      "Decoded sentence: Tome te te paite.\n",
      "\n",
      "-\n",
      "Input sentence: We try.\n",
      "Decoded sentence: Nous aites aite.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous aites aite.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous aites aite.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous aites aite.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous aites aite.\n",
      "\n",
      "-\n",
      "Input sentence: Ask Tom.\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Awesome!\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Be calm.\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Be calm.\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Be calm.\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Be cool.\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Arenez !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Arenez !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Arenez !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Arenez !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Arenez !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Arenez !\n",
      "\n",
      "-\n",
      "Input sentence: Be kind.\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Laisez-vous !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Laisez-vous !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Laisez-vous !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Laisez-vous !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Laisez-vous !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Laisez-vous !\n",
      "\n",
      "-\n",
      "Input sentence: Beat it.\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Call me.\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Call me.\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Call us.\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Call us.\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Come in.\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Come in.\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Come in.\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Come in.\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Come on!\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Come on.\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Come on.\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Come on.\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Drop it!\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Drop it!\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Drop it!\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Drop it!\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Get out!\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Get out!\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Get out!\n",
      "Decoded sentence: Arentez !\n",
      "\n",
      "-\n",
      "Input sentence: Get out.\n",
      "Decoded sentence: Arentez !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Next: inference mode (sampling).\n",
    "# Here's the drill:\n",
    "# 1) encode input and retrieve initial decoder state\n",
    "# 2) run one step of decoder with this initial state\n",
    "# and a \"start of sequence\" token as target.\n",
    "# Output will be the next target token\n",
    "# 3) Repeat with the current target token and current states\n",
    "import numpy as np\n",
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs,\n",
    "                      [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict((i, char) for char, \n",
    "                                i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, \n",
    "                                 i in target_token_index.items())\n",
    "max_decoder_seq_length = decoder_input_data.shape[1]\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or \n",
    "            len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training test)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assingment 3\n",
    "\n",
    "Tune the training algorithms for all RNN models above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "395px",
    "left": "0px",
    "right": "851.7px",
    "top": "110px",
    "width": "190px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
